---
title: "Data Frame Experiments"
author: "William V. Fullerton"
date: "2025-02-18"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Function Creation
```{r}
col_name <- function(data, x, y){
  # Check if the specified columns exist in the data frame
  if (!all(c(x, y) %in% names(data))) {
    stop("One or both of the specified columns do not exist in the data frame.")
  }
  
  # Extract the specified columns and return as a new data frame
  result <- data[, c(x, y), drop = FALSE]
  return(result)
}
```

#Testing
```{r}
col_name(data = Credit, x = "Balance", y = "Income")
```

#Making a Linear Model Function
```{r}
lin_mod <- function(data, x, y){
  # Check if the specified columns exist in the data frame
  if (!all(c(x, y) %in% names(data))) {
    stop("One or both of the specified columns do not exist in the data frame.")
  }
  
  # Extract the specified columns and return as a new data frame
  result <- data[, c(x, y), drop = FALSE]
  
  # Make a linear model using the correct formula
  formula <- as.formula(paste(y, "~", x))
  mod1 <- lm(formula, data = result)
  
  s <- summary(mod1)
  return(s)
}
```

#Test the function
```{r}
lin_mod(Credit, x = "Income", y = "Balance")
```

#Making an MSE Function
```{r}
MSE <- function(data, x, y){
  # Check if the specified columns exist in the data frame
  if (!all(c(x, y) %in% names(data))) {
    stop("One or both of the specified columns do not exist in the data frame.")
  }
  
  # Extract the specified columns and return as a new data frame
  result <- data[, c(x, y), drop = FALSE]
  
  #Create the training set
  training_data <- result[c(1:(nrow(result))*0.8),]
  
  #Create the testing set
  testing_data <- result[-c(1:(nrow(result))*0.8),]
  
  # Make a linear model using the correct formula from the training data set
  formula <- as.formula(paste(y, "~", x))
  mod1 <- lm(formula, data = training_data)
  
  #Isolate the y variable in the testing data set
  test <- testing_data[, y, drop = FALSE]
  
  #Find the predicted value
  pred <- predict(mod1, data.frame(test))
  
  #Find and save the MSE
  MSE <- mean((test - pred)^2)
  
  return(MSE)
}
```

#Test the function
```{r}
MSE(data = Credit, x = "Income", y = "Balance")
```

```{r}
MSE <- function(data, x, y) {
  # Check if the specified columns exist in the data frame
  if (!all(c(x, y) %in% names(data))) {
    stop("One or both of the specified columns do not exist in the data frame.")
  }
  
  # Extract the specified columns and return as a new data frame
  result <- data[, c(x, y), drop = FALSE]
  
  # Create the training set (80% of the data)
  set.seed(123)  # For reproducibility
  train_indices <- 1:floor(nrow(result) * 0.8)
  training_data <- result[train_indices, ]
  
  # Create the testing set (remaining 20% of the data)
  testing_data <- result[-train_indices, ]
  
  # Make a linear model using the correct formula from the training data set
  formula <- as.formula(paste(y, "~", x))
  mod1 <- lm(formula, data = training_data)
  
  # Find the predicted values using the testing data
  pred <- predict(mod1, newdata = testing_data)
  
  # Isolate the actual y variable in the testing data set
  actual <- testing_data[[y]]
  
  # Find and save the MSE
  mse_value <- mean((actual - pred)^2)
  
  return(mse_value)
}
```

```{r}
MSE(Credit, x = "Income", y = "Balance")
```

#Attempt with a Loess Curve
```{r}
MSE <- function(data, x, y) {
  # Check if the specified columns exist in the data frame
  if (!all(c(x, y) %in% names(data))) {
    stop("One or both of the specified columns do not exist in the data frame.")
  }
  
  # Extract the specified columns and return as a new data frame
  result <- data[, c(x, y), drop = FALSE]
  
  # Create the training set (80% of the data)
  set.seed(123)  # For reproducibility
  train_indices <- 1:floor(nrow(result) * 0.8)
  training_data <- result[train_indices, ]
  
  # Create the testing set (remaining 20% of the data)
  testing_data <- result[-train_indices, ]
  
  # Make a loose curve using the correct formula from the training data set
  formula <- as.formula(paste(y, "~", x))
  mod1 <- loess(formula, data = training_data)
  
  # Find the predicted values using the testing data
  pred <- predict(mod1, testing_data[[x]])
  
  # Isolate the actual y variable in the testing data set
  actual <- testing_data[[y]]
  
  # Find and save the MSE
  mse_value <- mean((actual - pred)^2)
  
  return(mse_value)
}
```

```{r}
MSE(Credit, x = "Income", y = "Balance")
```

#Try the function with a smooth spline curve
```{r}
MSE <- function(data, x, y) {
  # Check if the specified columns exist in the data frame
  if (!all(c(x, y) %in% names(data))) {
    stop("One or both of the specified columns do not exist in the data frame.")
  }
  
  # Extract the specified columns and return as a new data frame
  result <- data[, c(x, y), drop = FALSE]
  
  # Create the training set (80% of the data)
  set.seed(123)  # For reproducibility
  train_indices <- 1:floor(nrow(result) * 0.8)
  training_data <- result[train_indices, ]
  
  # Create the testing set (remaining 20% of the data)
  testing_data <- result[-train_indices, ]
  
  # Make a loose curve using the correct formula from the training data set
  mod1 <- smooth.spline(x = training_data[[x]], y = training_data[[y]])
  
  # Find the predicted values using the testing data
  pred <- predict(mod1, newdata = testing_data[[x]])$y
  
  # Isolate the actual y variable in the testing data set
  actual <- testing_data[[y]]
  
  # Find and save the MSE
  mse_value <- mean((actual - pred)^2)
  
  return(mse_value)
}
```

```{r}
MSE(Credit, x="Income", y="Balance")
```

#Best smooth spline df function
```{r}
Best_Smooth_Spline_df <- function(data, x, y, df_seq) {
  # Check if the specified columns exist in the data frame
  if (!all(c(x, y) %in% names(data))) {
    stop("One or both of the specified columns do not exist in the data frame.")
  }
  
  # Check if df_seq is empty
  if (length(df_seq) == 0) {
    stop("df_seq cannot be empty.")
  }
  
  # Check if the data has enough rows
  if (nrow(data) < 2) {
    stop("Data must have at least two rows.")
  }
  
  # Create storage vector for comparison of MSE values
  MSE <- numeric(length(df_seq))
  
  # Extract the specified columns and return as a new data frame
  result <- data[, c(x, y), drop = FALSE]
  
  # Create the training set (80% of the data)
  set.seed(123)  # For reproducibility
  train_indices <- 1:floor(nrow(result) * 0.8)
  training_data <- result[train_indices, ]
  
  # Create the testing set (remaining 20% of the data)
  testing_data <- result[-train_indices, ]
  
  #For loop for checking all of the span values against their MSEs per Loess model
  for(i in seq_along(df_seq)){
    smooth_spling_curve <- smooth.spline(x = training_data[[x]], y = training_data[[y]], 
                                         df = df_seq[i]) #Smooth spline model 
    
    # Find the predicted values using the testing data
    pred <- predict(smooth_spling_curve, newdata = testing_data[[x]])$y
  
    # Isolate the actual y variable in the testing data set
    actual <- testing_data[[y]]
  
    # Find and save the MSE values to their respective i index value
    MSE[i] <- mean((actual - pred)^2, na.rm = TRUE) 
  }
  
  #Created a data frame that connects each span value with its respective MSE value
  best_df <- data.frame(df = df_seq, MSE = MSE)
  
  #Return the best Span value
  return(best_df$df[best_df$MSE == min(best_df$MSE)])
}
```

#Test the function
```{r}
Best_Loess_Span(data = Credit, x = "Income", y = "Balance", span_seq = seq(1,0.1, -0.05))
```

```{r}
Best_Loess_Span(dft, "X", "Y", span_seq = seq(1,0.1, -0.05))
```

#Make the function work for a loess curve
```{r}
Best_Loess_Span <- function(data, x, y, span_seq) {
  # Check if the specified columns exist in the data frame
  if (!all(c(x, y) %in% names(data))) {
    stop("One or both of the specified columns do not exist in the data frame.")
  }
  
  # Check if span_seq is empty
  if (length(span_seq) == 0) {
    stop("span_seq cannot be empty.")
  }
  
  # Check if the data has enough rows
  if (nrow(data) < 2) {
    stop("Data must have at least two rows.")
  }
  
  # Create storage vector for comparison of MSE values
  MSE <- numeric(length(span_seq))
  
  # Extract the specified columns and return as a new data frame
  result <- data[, c(x, y), drop = FALSE]
  
  # Create the training set (80% of the data)
  set.seed(123)  # For reproducibility
  train_indices <- 1:floor(nrow(result) * 0.8)
  training_data <- result[train_indices, ]
  
  # Create the testing set (remaining 20% of the data)
  testing_data <- result[-train_indices, ]
  
  # Set formula for the loess model
  formula <- as.formula(paste(y, "~", x))
  
  #For loop for checking all of the span values against their MSEs per Loess model
  for(i in seq_along(span_seq)){
    loess_model <- loess(formula, data = training_data, span = span_seq[i]) #Loess model 
    
    # Find the predicted values using the testing data
    pred <- predict(loess_model, testing_data)
  
    # Isolate the actual y variable in the testing data set
    actual <- testing_data[[y]]
  
    # Find and save the MSE values to their respective i index value
    MSE[i] <- mean((actual - pred)^2, na.rm = TRUE) 
  }
  
  #Created a data frame that connects each span value with its respective MSE value
  best_span <- data.frame(span = span_seq, MSE = MSE)
  
  #Return the best Span value
  return(best_span$span[best_span$MSE == min(best_span$MSE)])
}
```

```{r}
Best_Smooth_Spline_df(dft, "X", "Y", df_seq = seq(100,10, by = -5))
```

